{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle challenge (cleaned up notebook).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/livjab/DS3-Kaggle-Comptetion/blob/master/Kaggle_challenge_(cleaned_up_notebook).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1voop2pbaoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiKYprDKbmk4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "b08192d4-0564-44ae-d858-a1e9523f398e"
      },
      "source": [
        "test = pd.read_csv(\"https://raw.githubusercontent.com/livjab/DS3-Kaggle-Comptetion/master/test_features.csv\")\n",
        "train = pd.read_csv(\"https://raw.githubusercontent.com/livjab/DS3-Kaggle-Comptetion/master/train_features.csv\")\n",
        "train_y = pd.read_csv(\"https://raw.githubusercontent.com/livjab/DS3-Kaggle-Comptetion/master/train_labels.csv\")\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>amount_tsh</th>\n",
              "      <th>date_recorded</th>\n",
              "      <th>funder</th>\n",
              "      <th>gps_height</th>\n",
              "      <th>installer</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>wpt_name</th>\n",
              "      <th>num_private</th>\n",
              "      <th>basin</th>\n",
              "      <th>subvillage</th>\n",
              "      <th>region</th>\n",
              "      <th>region_code</th>\n",
              "      <th>district_code</th>\n",
              "      <th>lga</th>\n",
              "      <th>ward</th>\n",
              "      <th>population</th>\n",
              "      <th>public_meeting</th>\n",
              "      <th>recorded_by</th>\n",
              "      <th>scheme_management</th>\n",
              "      <th>scheme_name</th>\n",
              "      <th>permit</th>\n",
              "      <th>construction_year</th>\n",
              "      <th>extraction_type</th>\n",
              "      <th>extraction_type_group</th>\n",
              "      <th>extraction_type_class</th>\n",
              "      <th>management</th>\n",
              "      <th>management_group</th>\n",
              "      <th>payment</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>water_quality</th>\n",
              "      <th>quality_group</th>\n",
              "      <th>quantity</th>\n",
              "      <th>quantity_group</th>\n",
              "      <th>source</th>\n",
              "      <th>source_type</th>\n",
              "      <th>source_class</th>\n",
              "      <th>waterpoint_type</th>\n",
              "      <th>waterpoint_type_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69572</td>\n",
              "      <td>6000.0</td>\n",
              "      <td>2011-03-14</td>\n",
              "      <td>Roman</td>\n",
              "      <td>1390</td>\n",
              "      <td>Roman</td>\n",
              "      <td>34.938093</td>\n",
              "      <td>-9.856322</td>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "      <td>Lake Nyasa</td>\n",
              "      <td>Mnyusi B</td>\n",
              "      <td>Iringa</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>Ludewa</td>\n",
              "      <td>Mundindi</td>\n",
              "      <td>109</td>\n",
              "      <td>True</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>VWC</td>\n",
              "      <td>Roman</td>\n",
              "      <td>False</td>\n",
              "      <td>1999</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>pay annually</td>\n",
              "      <td>annually</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "      <td>spring</td>\n",
              "      <td>spring</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013-03-06</td>\n",
              "      <td>Grumeti</td>\n",
              "      <td>1399</td>\n",
              "      <td>GRUMETI</td>\n",
              "      <td>34.698766</td>\n",
              "      <td>-2.147466</td>\n",
              "      <td>Zahanati</td>\n",
              "      <td>0</td>\n",
              "      <td>Lake Victoria</td>\n",
              "      <td>Nyamara</td>\n",
              "      <td>Mara</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>Serengeti</td>\n",
              "      <td>Natta</td>\n",
              "      <td>280</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>Other</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>2010</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>wug</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>never pay</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34310</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2013-02-25</td>\n",
              "      <td>Lottery Club</td>\n",
              "      <td>686</td>\n",
              "      <td>World vision</td>\n",
              "      <td>37.460664</td>\n",
              "      <td>-3.821329</td>\n",
              "      <td>Kwa Mahundi</td>\n",
              "      <td>0</td>\n",
              "      <td>Pangani</td>\n",
              "      <td>Majengo</td>\n",
              "      <td>Manyara</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>Simanjiro</td>\n",
              "      <td>Ngorika</td>\n",
              "      <td>250</td>\n",
              "      <td>True</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>VWC</td>\n",
              "      <td>Nyumba ya mungu pipe scheme</td>\n",
              "      <td>True</td>\n",
              "      <td>2009</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>pay per bucket</td>\n",
              "      <td>per bucket</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "      <td>dam</td>\n",
              "      <td>dam</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe multiple</td>\n",
              "      <td>communal standpipe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>67743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013-01-28</td>\n",
              "      <td>Unicef</td>\n",
              "      <td>263</td>\n",
              "      <td>UNICEF</td>\n",
              "      <td>38.486161</td>\n",
              "      <td>-11.155298</td>\n",
              "      <td>Zahanati Ya Nanyumbu</td>\n",
              "      <td>0</td>\n",
              "      <td>Ruvuma / Southern Coast</td>\n",
              "      <td>Mahakamani</td>\n",
              "      <td>Mtwara</td>\n",
              "      <td>90</td>\n",
              "      <td>63</td>\n",
              "      <td>Nanyumbu</td>\n",
              "      <td>Nanyumbu</td>\n",
              "      <td>58</td>\n",
              "      <td>True</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>VWC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>1986</td>\n",
              "      <td>submersible</td>\n",
              "      <td>submersible</td>\n",
              "      <td>submersible</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>never pay</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>dry</td>\n",
              "      <td>dry</td>\n",
              "      <td>machine dbh</td>\n",
              "      <td>borehole</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe multiple</td>\n",
              "      <td>communal standpipe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19728</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011-07-13</td>\n",
              "      <td>Action In A</td>\n",
              "      <td>0</td>\n",
              "      <td>Artisan</td>\n",
              "      <td>31.130847</td>\n",
              "      <td>-1.825359</td>\n",
              "      <td>Shuleni</td>\n",
              "      <td>0</td>\n",
              "      <td>Lake Victoria</td>\n",
              "      <td>Kyanyamisa</td>\n",
              "      <td>Kagera</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>Karagwe</td>\n",
              "      <td>Nyakasimbi</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>never pay</td>\n",
              "      <td>never pay</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>seasonal</td>\n",
              "      <td>seasonal</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  amount_tsh  ...              waterpoint_type waterpoint_type_group\n",
              "0  69572      6000.0  ...           communal standpipe    communal standpipe\n",
              "1   8776         0.0  ...           communal standpipe    communal standpipe\n",
              "2  34310        25.0  ...  communal standpipe multiple    communal standpipe\n",
              "3  67743         0.0  ...  communal standpipe multiple    communal standpipe\n",
              "4  19728         0.0  ...           communal standpipe    communal standpipe\n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9hJXnHQbpRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "503a022c-d37d-43da-c3b0-6c5f0cae7768"
      },
      "source": [
        "# fast first baseline\n",
        "\n",
        "train_y[\"status_group\"].value_counts(normalize=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "functional                 0.543081\n",
              "non functional             0.384242\n",
              "functional needs repair    0.072677\n",
              "Name: status_group, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPPOmY9abtig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecc16949-11ba-49e9-cb03-0e19410aa3ad"
      },
      "source": [
        "# going to combine train_y with train for ease\n",
        "\n",
        "train = pd.merge(train, train_y)\n",
        "train.shape, test.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((59400, 41), (14358, 40))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z26EV2Dcu9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(df):\n",
        "  \n",
        "  # separating date into year/month/day\n",
        "  df[\"date_recorded_sep\"] = train[\"date_recorded\"].str.split(\"-\")\n",
        "  \n",
        "  # create new features for each\n",
        "  df[\"year_recorded\"] = pd.to_numeric(df[\"date_recorded_sep\"].str[0])\n",
        "  df[\"month_recorded\"] = pd.to_numeric(df[\"date_recorded_sep\"].str[1])\n",
        "  df[\"day_of_month_recorded\"] = pd.to_numeric(df[\"date_recorded_sep\"].str[2])\n",
        "  \n",
        "  # drop separated column\n",
        "  df = df.drop(columns=\"date_recorded_sep\")\n",
        "  \n",
        "  \n",
        "  # changing public_meeting to 0/1\n",
        "  df[\"public_meeting\"] = df.public_meeting.fillna(value=\"True\")\n",
        "  df[\"public_meeting\"] = df.public_meeting.astype(bool).astype(int)\n",
        "  \n",
        "  # changing permit to 0/1\n",
        "  df[\"permit\"] = df.permit.fillna(value=\"True\")\n",
        "  df[\"permit\"] = df.permit.astype(bool).astype(int)\n",
        "  \n",
        "  \n",
        "  # drop the following features due to repetition and/or insignificance\n",
        "  df = df.drop(columns=[\"id\", # random number\n",
        "                        \"recorded_by\", # same entry in every row\n",
        "                        \"extraction_type\", # basically a duplicate\n",
        "                        \"extraction_type_group\", # another near duplicate\n",
        "                        \"payment\", # has a near duplicate\n",
        "                        \"water_quality\", # has a near duplicate\n",
        "                        \"quantity_group\", # has an exact duplicate\n",
        "                        \"source_type\", # heas a near duplicate\n",
        "                        \"waterpoint_type_group\"]) # has a near duplicate\n",
        "  \n",
        "  # feature engineering\n",
        "  \n",
        "  # create age\n",
        "  df[\"age_of_pump\"] = df[\"year_recorded\"] - df[\"construction_year\"]\n",
        "  \n",
        "  # water per person\n",
        "  #df[\"water_per_person\"] = df[\"amount_tsh\"] / df[\"population\"]\n",
        "  \n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAGMOWByXre2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "outputId": "5d1d209c-de60-42d6-fff9-d590402ef177"
      },
      "source": [
        "train.dtypes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                         int64\n",
              "amount_tsh               float64\n",
              "date_recorded             object\n",
              "funder                    object\n",
              "gps_height                 int64\n",
              "installer                 object\n",
              "longitude                float64\n",
              "latitude                 float64\n",
              "wpt_name                  object\n",
              "num_private                int64\n",
              "basin                     object\n",
              "subvillage                object\n",
              "region                    object\n",
              "region_code                int64\n",
              "district_code              int64\n",
              "lga                       object\n",
              "ward                      object\n",
              "population                 int64\n",
              "public_meeting            object\n",
              "recorded_by               object\n",
              "scheme_management         object\n",
              "scheme_name               object\n",
              "permit                    object\n",
              "construction_year          int64\n",
              "extraction_type           object\n",
              "extraction_type_group     object\n",
              "extraction_type_class     object\n",
              "management                object\n",
              "management_group          object\n",
              "payment                   object\n",
              "payment_type              object\n",
              "water_quality             object\n",
              "quality_group             object\n",
              "quantity                  object\n",
              "quantity_group            object\n",
              "source                    object\n",
              "source_type               object\n",
              "source_class              object\n",
              "waterpoint_type           object\n",
              "waterpoint_type_group     object\n",
              "status_group              object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgjH-gqLiSeW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "4f6e9974-14db-4998-dcb8-da51cf2ea888"
      },
      "source": [
        "train = clean(train)\n",
        "X_train = train.drop(columns=\"status_group\")\n",
        "y_train = train[\"status_group\"]\n",
        "X_train.head()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amount_tsh</th>\n",
              "      <th>date_recorded</th>\n",
              "      <th>funder</th>\n",
              "      <th>gps_height</th>\n",
              "      <th>installer</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>wpt_name</th>\n",
              "      <th>num_private</th>\n",
              "      <th>basin</th>\n",
              "      <th>subvillage</th>\n",
              "      <th>region</th>\n",
              "      <th>region_code</th>\n",
              "      <th>district_code</th>\n",
              "      <th>lga</th>\n",
              "      <th>ward</th>\n",
              "      <th>population</th>\n",
              "      <th>public_meeting</th>\n",
              "      <th>scheme_management</th>\n",
              "      <th>scheme_name</th>\n",
              "      <th>permit</th>\n",
              "      <th>construction_year</th>\n",
              "      <th>extraction_type_class</th>\n",
              "      <th>management</th>\n",
              "      <th>management_group</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>quality_group</th>\n",
              "      <th>quantity</th>\n",
              "      <th>source</th>\n",
              "      <th>source_class</th>\n",
              "      <th>waterpoint_type</th>\n",
              "      <th>year_recorded</th>\n",
              "      <th>month_recorded</th>\n",
              "      <th>day_of_month_recorded</th>\n",
              "      <th>age_of_pump</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6000.0</td>\n",
              "      <td>2011-03-14</td>\n",
              "      <td>Roman</td>\n",
              "      <td>1390</td>\n",
              "      <td>Roman</td>\n",
              "      <td>34.938093</td>\n",
              "      <td>-9.856322</td>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "      <td>Lake Nyasa</td>\n",
              "      <td>Mnyusi B</td>\n",
              "      <td>Iringa</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>Ludewa</td>\n",
              "      <td>Mundindi</td>\n",
              "      <td>109</td>\n",
              "      <td>1</td>\n",
              "      <td>VWC</td>\n",
              "      <td>Roman</td>\n",
              "      <td>0</td>\n",
              "      <td>1999</td>\n",
              "      <td>gravity</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>annually</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>spring</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>2011</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2013-03-06</td>\n",
              "      <td>Grumeti</td>\n",
              "      <td>1399</td>\n",
              "      <td>GRUMETI</td>\n",
              "      <td>34.698766</td>\n",
              "      <td>-2.147466</td>\n",
              "      <td>Zahanati</td>\n",
              "      <td>0</td>\n",
              "      <td>Lake Victoria</td>\n",
              "      <td>Nyamara</td>\n",
              "      <td>Mara</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>Serengeti</td>\n",
              "      <td>Natta</td>\n",
              "      <td>280</td>\n",
              "      <td>1</td>\n",
              "      <td>Other</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "      <td>gravity</td>\n",
              "      <td>wug</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>good</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>2013</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25.0</td>\n",
              "      <td>2013-02-25</td>\n",
              "      <td>Lottery Club</td>\n",
              "      <td>686</td>\n",
              "      <td>World vision</td>\n",
              "      <td>37.460664</td>\n",
              "      <td>-3.821329</td>\n",
              "      <td>Kwa Mahundi</td>\n",
              "      <td>0</td>\n",
              "      <td>Pangani</td>\n",
              "      <td>Majengo</td>\n",
              "      <td>Manyara</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>Simanjiro</td>\n",
              "      <td>Ngorika</td>\n",
              "      <td>250</td>\n",
              "      <td>1</td>\n",
              "      <td>VWC</td>\n",
              "      <td>Nyumba ya mungu pipe scheme</td>\n",
              "      <td>1</td>\n",
              "      <td>2009</td>\n",
              "      <td>gravity</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>per bucket</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>dam</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe multiple</td>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2013-01-28</td>\n",
              "      <td>Unicef</td>\n",
              "      <td>263</td>\n",
              "      <td>UNICEF</td>\n",
              "      <td>38.486161</td>\n",
              "      <td>-11.155298</td>\n",
              "      <td>Zahanati Ya Nanyumbu</td>\n",
              "      <td>0</td>\n",
              "      <td>Ruvuma / Southern Coast</td>\n",
              "      <td>Mahakamani</td>\n",
              "      <td>Mtwara</td>\n",
              "      <td>90</td>\n",
              "      <td>63</td>\n",
              "      <td>Nanyumbu</td>\n",
              "      <td>Nanyumbu</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>VWC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1986</td>\n",
              "      <td>submersible</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>good</td>\n",
              "      <td>dry</td>\n",
              "      <td>machine dbh</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe multiple</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2011-07-13</td>\n",
              "      <td>Action In A</td>\n",
              "      <td>0</td>\n",
              "      <td>Artisan</td>\n",
              "      <td>31.130847</td>\n",
              "      <td>-1.825359</td>\n",
              "      <td>Shuleni</td>\n",
              "      <td>0</td>\n",
              "      <td>Lake Victoria</td>\n",
              "      <td>Kyanyamisa</td>\n",
              "      <td>Kagera</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>Karagwe</td>\n",
              "      <td>Nyakasimbi</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>gravity</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>never pay</td>\n",
              "      <td>good</td>\n",
              "      <td>seasonal</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>2011</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>2011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   amount_tsh date_recorded  ... day_of_month_recorded  age_of_pump\n",
              "0      6000.0    2011-03-14  ...                    14           12\n",
              "1         0.0    2013-03-06  ...                     6            3\n",
              "2        25.0    2013-02-25  ...                    25            4\n",
              "3         0.0    2013-01-28  ...                    28           27\n",
              "4         0.0    2011-07-13  ...                    13         2011\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxu5cs6XidYW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "754fa8df-5580-4478-cb8a-e68b9c1f5172"
      },
      "source": [
        "X_test = clean(test)\n",
        "X_test.shape, X_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14358, 35), (59400, 35))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88mtli8ibwPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "7acd9a6d-f380-4666-a111-f2abd72f6c64"
      },
      "source": [
        "train.isnull().sum().sort_values(ascending=False).head(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scheme_name          28166\n",
              "scheme_management     3877\n",
              "installer             3655\n",
              "funder                3635\n",
              "subvillage             371\n",
              "age_of_pump              0\n",
              "lga                      0\n",
              "district_code            0\n",
              "region_code              0\n",
              "region                   0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AykJpzRVjSOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "cc772175-a582-488b-97a9-03d5a96b2cff"
      },
      "source": [
        "numeric_columns = train.select_dtypes(include=\"number\").columns\n",
        "numeric_columns.tolist()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['amount_tsh',\n",
              " 'gps_height',\n",
              " 'longitude',\n",
              " 'latitude',\n",
              " 'num_private',\n",
              " 'region_code',\n",
              " 'district_code',\n",
              " 'population',\n",
              " 'public_meeting',\n",
              " 'permit',\n",
              " 'construction_year',\n",
              " 'year_recorded',\n",
              " 'month_recorded',\n",
              " 'day_of_month_recorded',\n",
              " 'age_of_pump']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qntytce-jl9I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "2b5d1b34-1aaf-4e26-92e0-972305d0d800"
      },
      "source": [
        "categorical_columns = train.select_dtypes(exclude=\"number\").columns\n",
        "categorical_columns = categorical_columns.drop(\"status_group\")\n",
        "categorical_columns.tolist()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['date_recorded',\n",
              " 'funder',\n",
              " 'installer',\n",
              " 'wpt_name',\n",
              " 'basin',\n",
              " 'subvillage',\n",
              " 'region',\n",
              " 'lga',\n",
              " 'ward',\n",
              " 'scheme_management',\n",
              " 'scheme_name',\n",
              " 'extraction_type_class',\n",
              " 'management',\n",
              " 'management_group',\n",
              " 'payment_type',\n",
              " 'quality_group',\n",
              " 'quantity',\n",
              " 'source',\n",
              " 'source_class',\n",
              " 'waterpoint_type']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ovFjRUD8gfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "063b8fc7-fff8-4438-a39d-fdcf3dd86259"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "# We create the preprocessing pipelines for both numeric and categorical data.\n",
        "numeric_features = numeric_columns\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = categorical_columns\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', LogisticRegression(solver='lbfgs'))])\n",
        "\n",
        "X = train.drop('status_group', axis=1)\n",
        "y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model score: 0.783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOrSmMfUnAyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "48152f54-d204-416f-a05f-1c9088b8fdbd"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# We create the preprocessing pipelines for both numeric and categorical data.\n",
        "numeric_features = numeric_columns\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = categorical_columns\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', RandomForestClassifier(max_depth=8))])\n",
        "\n",
        "X = train.drop('status_group', axis=1)\n",
        "y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model score: 0.572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhoYkSx6DaKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a01b0b6c-2b44-42b7-e43b-c28d335e7424"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# We create the preprocessing pipelines for both numeric and categorical data.\n",
        "numeric_features = numeric_columns\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = categorical_columns\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', XGBClassifier(max_depth=8))])\n",
        "\n",
        "X = train.drop('status_group', axis=1)\n",
        "y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model score: 0.786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTD2Ml4qEYBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "16453960-b716-46b1-8310-c3a2ce441770"
      },
      "source": [
        "# going to make another submission since this has beat my other scores\n",
        "\n",
        "y_pred = clf.predict(test)\n",
        "\n",
        "sample_submission = pd.read_csv('https://raw.githubusercontent.com/livjab/DS3-Kaggle-Comptetion/master/sample_submission.csv')\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "\n",
        "from google.colab import files\n",
        "submission.to_csv('LJ-fourth-submission.csv', index=False)\n",
        "files.download('LJ-fourth-submission.csv')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1494: FutureWarning: \n",
            "Passing list-likes to .loc or [] with any missing label will raise\n",
            "KeyError in the future, you can use .reindex() as an alternative.\n",
            "\n",
            "See the documentation here:\n",
            "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
            "  return self._getitem_tuple(key)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhA42_19GWMQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "96c6c453-491a-487e-df2d-2d341d9a5a31"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/a1/f7a22f144f33be78afeb06bfa78478e8284a64263a3c09b1ef54e673841e/category_encoders-2.0.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.21.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.16.3)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.3.0)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.12.5)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg4wvReqkD-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fa1a659-0a66-434d-e164-3284f0c121d7"
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# We create the preprocessing pipelines for both numeric and categorical data.\n",
        "numeric_features = numeric_columns\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = categorical_columns\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('ordinal', ce.OrdinalEncoder())])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', XGBClassifier(max_depth=7))])\n",
        "\n",
        "X = train.drop('status_group', axis=1)\n",
        "y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model score: 0.783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWeaNcJi9qxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "a2d2d8ef-c3ab-4008-e7b9-bb6bfcf4463b"
      },
      "source": [
        "# slowly bumping up, going to submit this score as well\n",
        "\n",
        "y_pred = clf.predict(test)\n",
        "\n",
        "sample_submission = pd.read_csv('https://raw.githubusercontent.com/livjab/DS3-Kaggle-Comptetion/master/sample_submission.csv')\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "\n",
        "from google.colab import files\n",
        "submission.to_csv('LJ-fifth-submission.csv', index=False)\n",
        "files.download('LJ-fifth-submission.csv')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1494: FutureWarning: \n",
            "Passing list-likes to .loc or [] with any missing label will raise\n",
            "KeyError in the future, you can use .reindex() as an alternative.\n",
            "\n",
            "See the documentation here:\n",
            "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
            "  return self._getitem_tuple(key)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaxaU6_EJWR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "5bee9289-4fc4-43c3-ba8b-ca40e1ce35e2"
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "preprocessor = make_pipeline(ce.OrdinalEncoder(), \n",
        "                             StandardScaler(), \n",
        "                             SimpleImputer())\n",
        "\n",
        "features = train.drop(columns=\"status_group\")\n",
        "target = \"status_group\"\n",
        "\n",
        "X_train = preprocessor.fit_transform(features)\n",
        "X_test = preprocessor.transform(features)\n",
        "\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = train[target]\n",
        "\n",
        "\n",
        "scores = cross_validate(XGBClassifier(max_depth=5, n_estimators=100), \n",
        "                        X_train, \n",
        "                        y_train, \n",
        "                        scoring=\"accuracy\",\n",
        "                        cv=3, \n",
        "                        return_train_score=True, \n",
        "                        return_estimator=True)\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26.712742</td>\n",
              "      <td>0.394750</td>\n",
              "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
              "      <td>0.772172</td>\n",
              "      <td>0.789091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26.751808</td>\n",
              "      <td>0.385004</td>\n",
              "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
              "      <td>0.773636</td>\n",
              "      <td>0.789217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.532731</td>\n",
              "      <td>0.353785</td>\n",
              "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
              "      <td>0.734394</td>\n",
              "      <td>0.790278</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    fit_time  score_time  ... test_score  train_score\n",
              "0  26.712742    0.394750  ...   0.772172     0.789091\n",
              "1  26.751808    0.385004  ...   0.773636     0.789217\n",
              "2  26.532731    0.353785  ...   0.734394     0.790278\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY50xnWrVh2i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "2433426f-a0b2-4d2f-96e9-38c0dc946f47"
      },
      "source": [
        "!pip install xgboost --upgrade"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xgboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/24/5fe7237b2eca13ee0cfb100bec8c23f4e69ce9df852a64b0493d49dae4e0/xgboost-0.90-py2.py3-none-manylinux1_x86_64.whl (142.8MB)\n",
            "\u001b[K     |████████████████████████████████| 142.8MB 166kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.16.3)\n",
            "Installing collected packages: xgboost\n",
            "  Found existing installation: xgboost 0.82\n",
            "    Uninstalling xgboost-0.82:\n",
            "      Successfully uninstalled xgboost-0.82\n",
            "Successfully installed xgboost-0.90\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "xgboost"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-BFyDVniLcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "86fb01ee-a1f3-4ce0-f6c6-525ad95f5687"
      },
      "source": [
        "numeric_columns = train.select_dtypes(include=\"number\").columns\n",
        "numeric_columns.tolist()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['amount_tsh',\n",
              " 'gps_height',\n",
              " 'longitude',\n",
              " 'latitude',\n",
              " 'num_private',\n",
              " 'region_code',\n",
              " 'district_code',\n",
              " 'population',\n",
              " 'public_meeting',\n",
              " 'permit',\n",
              " 'construction_year',\n",
              " 'year_recorded',\n",
              " 'month_recorded',\n",
              " 'day_of_month_recorded',\n",
              " 'age_of_pump']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mynZCWgoQlx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "f69b3fff-c926-4798-c0ec-50e922b4c769"
      },
      "source": [
        "features = numeric_columns\n",
        "target = \"status_group\"\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "\n",
        "scores = cross_validate(XGBClassifier(max_depth=6, n_estimators=100),\n",
        "                       X_train,\n",
        "                       y_train,\n",
        "                       scoring=\"accuracy\",\n",
        "                       cv=3,\n",
        "                       return_train_score=True,\n",
        "                       return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16.508260</td>\n",
              "      <td>0.447404</td>\n",
              "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
              "      <td>0.691111</td>\n",
              "      <td>0.716742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.249008</td>\n",
              "      <td>0.452722</td>\n",
              "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
              "      <td>0.688131</td>\n",
              "      <td>0.717323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16.518125</td>\n",
              "      <td>0.454373</td>\n",
              "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
              "      <td>0.679697</td>\n",
              "      <td>0.714949</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    fit_time  score_time  ... test_score  train_score\n",
              "0  16.508260    0.447404  ...   0.691111     0.716742\n",
              "1  16.249008    0.452722  ...   0.688131     0.717323\n",
              "2  16.518125    0.454373  ...   0.679697     0.714949\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKO2jw8DbANR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "a38f9504-2099-4f58-fa7a-f169a39bf867"
      },
      "source": [
        "features = categorical_columns\n",
        "target = \"status_group\"\n",
        "\n",
        "encoded = ce.OrdinalEncoder()\n",
        "X_train = encoded.fit_transform(train[features])\n",
        "X_test = encoded.transform(test[features])\n",
        "\n",
        "y_train = train[target]\n",
        "\n",
        "scores = cross_validate(XGBClassifier(max_depth=6, n_estimators=100),\n",
        "                       X_train,\n",
        "                       y_train,\n",
        "                       scoring=\"accuracy\",\n",
        "                       cv=3,\n",
        "                       return_train_score=True,\n",
        "                       return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.816829</td>\n",
              "      <td>0.430025</td>\n",
              "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
              "      <td>0.770051</td>\n",
              "      <td>0.793864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.551333</td>\n",
              "      <td>0.438449</td>\n",
              "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
              "      <td>0.775960</td>\n",
              "      <td>0.796717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20.342627</td>\n",
              "      <td>0.371897</td>\n",
              "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.793207</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    fit_time  score_time  ... test_score  train_score\n",
              "0  20.816829    0.430025  ...   0.770051     0.793864\n",
              "1  20.551333    0.438449  ...   0.775960     0.796717\n",
              "2  20.342627    0.371897  ...   0.705000     0.793207\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb_x0XQAmlCZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "2e3b461d-c7a8-4ec0-8aa6-da4c3dd057e0"
      },
      "source": [
        "# just going to continue to iterate on my best model and play areound with feature selection\n",
        "\n",
        "numeric_features = [\"amount_tsh\", \"year_recorded\", \"age of pump\", \"public_meeting\", \"construction_year\"]\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = [\"basin\", \"source_class\", \"quantity\"]\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', XGBClassifier(max_depth=8))])\n",
        "\n",
        "#X = train.drop('status_group', axis=1)\n",
        "#y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-26302d176777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model score: %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_validate_remainder\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_column_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0mremaining_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         raise ValueError(\"No valid specification of the columns. Only a \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         raise ValueError(\"No valid specification of the columns. Only a \"\n",
            "\u001b[0;31mValueError\u001b[0m: 'age of pump' is not in list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwWrD6-8yx5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_features = [\"amount_tsh\", \"year_recorded\", \"age of pump\", \"public_meeting\", \"construction_year\"]\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = [\"basin\", \"source_class\", \"quantity\", \"source\", \"region\"]\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', XGBClassifier(max_depth=7))])\n",
        "\n",
        "X = train.drop('status_group', axis=1)\n",
        "y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loZVDDjQ0oDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_features = [\"amount_tsh\", \"year_recorded\", \"age of pump\", \"public_meeting\", \"construction_year\"]\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = [\"basin\", \"source_class\", \"quantity\", \"source\", \"region\", \"waterpoint_type\"]\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', XGBClassifier(max_depth=7))])\n",
        "\n",
        "X = train.drop('status_group', axis=1)\n",
        "y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACIOYIGs1kk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_4soAUi1lzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_features = [\"amount_tsh\", \"year_recorded\", \"age of pump\", \"public_meeting\", \"construction_year\"]\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = [\"basin\", \"source_class\", \"quantity\", \"source\", \"region\", \"waterpoint_type\", \"quality_group\", \"extraction_type_class\"]\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', XGBClassifier(max_depth=7))])\n",
        "\n",
        "X = train.drop('status_group', axis=1)\n",
        "y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3yz5-w2337tJ",
        "colab": {}
      },
      "source": [
        "numeric_features = [\"amount_tsh\", \"year_recorded\", \"age of pump\", \"public_meeting\", \"construction_year\"]\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = [\"basin\", \"source_class\", \"quantity\", \"source\", \"region\", \"waterpoint_type\", \"quality_group\", \"extraction_type_class\"]\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('ordinal', ce.OrdinalEncoder())])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', XGBClassifier(max_depth=8))])\n",
        "\n",
        "X = train.drop('status_group', axis=1)\n",
        "y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD6sWKmM3-ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_features = [\"amount_tsh\", \"year_recorded\", \"age of pump\", \"public_meeting\", \"construction_year\"]\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['date_recorded', 'funder', 'installer', 'wpt_name', 'basin',\n",
        "       'subvillage', 'region', 'lga', 'ward', 'scheme_management',\n",
        "       'scheme_name', 'extraction_type_class', 'management',\n",
        "       'management_group', 'payment_type', 'quality_group', 'quantity',\n",
        "       'source', 'source_class', 'waterpoint_type']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('ordinal', ce.OrdinalEncoder())])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', XGBClassifier(max_depth=8))])\n",
        "\n",
        "X = train.drop('status_group', axis=1)\n",
        "y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8UE4uLw4GQz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3010c76b-8435-40de-f851-bc471081c0b9"
      },
      "source": [
        "numeric_features = [\"amount_tsh\", \"year_recorded\", \"construction_year\"]\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['date_recorded', 'funder', 'installer', 'wpt_name', 'basin',\n",
        "       'subvillage', 'region', 'lga', 'ward', 'scheme_management',\n",
        "       'scheme_name', 'extraction_type_class', 'management',\n",
        "       'management_group', 'payment_type', 'quality_group', 'quantity',\n",
        "       'source', 'source_class', 'waterpoint_type']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('ordinal', ce.OrdinalEncoder())])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', XGBClassifier(max_depth=8))])\n",
        "\n",
        "X = train.drop('status_group', axis=1)\n",
        "y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model score: 0.787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZC-ohq9erMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbf4d1ef-e47d-4131-a576-152401baa443"
      },
      "source": [
        "numeric_features = [\"amount_tsh\", \"construction_year\"]\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['funder', 'installer', 'wpt_name', 'basin',\n",
        "       'subvillage', 'region', 'lga', 'ward', 'scheme_management',\n",
        "       'scheme_name', 'extraction_type_class', 'management',\n",
        "       'management_group', 'payment_type', 'quality_group', 'quantity',\n",
        "       'source', 'source_class', 'waterpoint_type']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('ordinal', ce.OrdinalEncoder())])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', XGBClassifier(max_depth=8))])\n",
        "\n",
        "X = train.drop('status_group', axis=1)\n",
        "y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model score: 0.780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unAEgB_DfE3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a64eb45-4fdd-492b-9c53-faf3c4b8916a"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "numeric_features = [\"latitude\", \"longitude\", \"amount_tsh\", \"age_of_pump\"]\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['quantity', 'waterpoint_type', \"extraction_type_class\", \"payment_type\", \"lga\"]\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('ordinal', ce.OrdinalEncoder())])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', XGBClassifier(max_depth=8))])\n",
        "\n",
        "X = train.drop('status_group', axis=1)\n",
        "y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model score: 0.795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1pWieAqG1Yw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "13a1e65c-9310-4683-fc09-fcdf31ad225c"
      },
      "source": [
        "# going to submit this score as well\n",
        "\n",
        "y_pred = clf.predict(test)\n",
        "\n",
        "sample_submission = pd.read_csv('https://raw.githubusercontent.com/livjab/DS3-Kaggle-Comptetion/master/sample_submission.csv')\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "\n",
        "from google.colab import files\n",
        "submission.to_csv('LJ-fifth-submission.csv', index=False)\n",
        "files.download('LJ-fifth-submission.csv')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1494: FutureWarning: \n",
            "Passing list-likes to .loc or [] with any missing label will raise\n",
            "KeyError in the future, you can use .reindex() as an alternative.\n",
            "\n",
            "See the documentation here:\n",
            "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
            "  return self._getitem_tuple(key)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZyMKuMdHNrE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d76596c0-e36a-46c9-865d-cb78ea2d7b61"
      },
      "source": [
        "numeric_features = [\"latitude\", \"longitude\", \"amount_tsh\", \"age_of_pump\"]\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['quantity', 'waterpoint_type', \"extraction_type_class\", \"payment_type\", \"lga\"]\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('ordinal', ce.OrdinalEncoder())])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Append classifier to preprocessing pipeline.\n",
        "# Now we have a full prediction pipeline.\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', XGBClassifier(max_depth=7, n_estimators=200))])\n",
        "\n",
        "X = train.drop('status_group', axis=1)\n",
        "y = train['status_group']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model score: 0.784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj7YQXtaHtu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}